{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pumafi/problem_solving_rl_pumafi/blob/main/grid_encoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLBEvBpgYjNo",
        "outputId": "53a8828d-16ea-45c0-b40d-88fbce1d2e01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'problem_solving_rl_pumafi'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 23 (delta 3), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (23/23), 17.99 MiB | 13.28 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n",
            "/content/problem_solving_rl_pumafi\n"
          ]
        }
      ],
      "source": [
        "RUNNING_IN_COLAB = True\n",
        "\n",
        "%cd /content\n",
        "\n",
        "if RUNNING_IN_COLAB:\n",
        "    REPO_URL = 'https://github.com/Pumafi/problem_solving_rl_pumafi'\n",
        "    BRANCH   = 'main'\n",
        "    REPO_DIR = 'problem_solving_rl_pumafi'\n",
        "\n",
        "    from pathlib import Path\n",
        "\n",
        "    if Path(REPO_DIR).is_dir():\n",
        "      !rm -rf {REPO_DIR}\n",
        "\n",
        "    # Download the repository\n",
        "    if not Path(REPO_DIR).is_dir():\n",
        "        !git clone --branch {BRANCH} --depth=1 -- {REPO_URL} {REPO_DIR}\n",
        "\n",
        "    %cd {REPO_DIR}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "from tqdm.notebook import trange, tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "\n",
        "\n",
        "from scipy.stats import kde\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "wuqLpqehYmQ2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LvOiHKzWiOfe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load code from the repo\n",
        "from utils.data_handling import get_color_map, pad_to_shape, preprocess_challenge_data\n",
        "from utils.preprocess_metalearning_data import filter_and_split_inputs\n",
        "from models.autoencoder import AutoEncoder"
      ],
      "metadata": {
        "id": "XnQHErZ4YmUO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def load_json(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "training_challenges = load_json('./data/arc-agi_training_challenges.json')\n",
        "training_solutions = load_json('./data/arc-agi_training_solutions.json')\n",
        "evaluation_challenges = load_json('./data/arc-agi_evaluation_challenges.json')\n",
        "\n",
        "print(\"Data loaded successfully.\")\n",
        "print(f\"Training tasks: {len(training_challenges)}\")\n",
        "print(f\"Evaluation tasks: {len(evaluation_challenges)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Krvii9ISYmXN",
        "outputId": "908b80c7-ce45-4ffc-f0aa-d1fe85f1dc0a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n",
            "Training tasks: 400\n",
            "Evaluation tasks: 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all inputs for meta learning, then the training data for latter\n",
        "challenge_propositioner_inputs, _, _, _, _ = preprocess_challenge_data(training_challenges, training_solutions)\n",
        "print(len(challenge_propositioner_inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoDrfYxudPi0",
        "outputId": "803babde-55a7-47dc-856b-db451346488d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In order of access we have:\n",
        "#     challenge_propositioner_inputs [problem_nb (list)] [example_nb (list)] [0/1 - input/output (tuple)] -> [30, 30, 10] (ndarray)\n",
        "\n",
        "# Visualize the size of examples sets (NB: All have at least 2 examples, but 2 is to few for my idea)\n",
        "for i in range(5):\n",
        "  print(\"Problem nb \", i +1, \" | nb examples: \", len(challenge_propositioner_inputs[i]))\n",
        "\n",
        "print(\"\\nSize of one grid: \", challenge_propositioner_inputs[0][0][0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv3v5iekYs4N",
        "outputId": "97647296-8f6c-42b8-aaed-c3accfc13878"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem nb  1  | nb examples:  5\n",
            "Problem nb  2  | nb examples:  5\n",
            "Problem nb  3  | nb examples:  3\n",
            "Problem nb  4  | nb examples:  2\n",
            "Problem nb  5  | nb examples:  3\n",
            "\n",
            "Size of one grid:  (30, 30, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flattened_challenges = [\n",
        "    x\n",
        "    for xss in challenge_propositioner_inputs\n",
        "    for xs in xss\n",
        "    for x in xs\n",
        "]\n",
        "\n",
        "flattened_challenges = np.array(flattened_challenges)\n",
        "\n",
        "print(flattened_challenges.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2jDTzmcdYv0",
        "outputId": "a081e647-62b7-4c01-bd5d-0a9cb4980312"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2604, 30, 30, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cmap, norm = get_color_map(number_of_categories=9)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('input')\n",
        "plt.imshow(np.argmax(challenge_propositioner_inputs[0][0][0], axis=-1), interpolation='nearest', cmap=cmap, norm=norm)\n",
        "plt.axis('off')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('output')\n",
        "plt.imshow(np.argmax(challenge_propositioner_inputs[0][0][1], axis=-1), interpolation='nearest', cmap=cmap, norm=norm)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "_tkp6Um0aUm1",
        "outputId": "b0362feb-5ab0-401d-b4df-17ca62bbc23e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NB: for this and place cell, get inspiration from GANs, variational distance for Kozachenko-Leonenko, as well as initializing the ccenter of massesf\n",
        "\n",
        "autoencoder = AutoEncoder()\n",
        "autoencoder.compile(optimizer=keras.optimizers.Adam(learning_rate=5e-4), loss=losses.CategoricalCrossentropy())\n",
        "autoencoder.build([None, flattened_challenges.shape[1], flattened_challenges.shape[2], 10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BmHW-rTctV3",
        "outputId": "1ed33411-0549-4f87-88d1-801a6a4461cf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'auto_encoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_imgs = autoencoder.encoder(flattened_challenges[:2]).numpy()\n",
        "decoded_imgs = autoencoder.decoder(encoded_imgs[:2]).numpy()"
      ],
      "metadata": {
        "id": "g-DXsr58dphx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.encoder.load_weights(\"weights/weigts-encoder.weights.h5\")\n",
        "autoencoder.decoder.load_weights(\"weights/weigts-decoder.weights.h5\")"
      ],
      "metadata": {
        "id": "k8vo9qQxdiO8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_imgs = autoencoder.encoder(flattened_challenges[:11]).numpy()\n",
        "decoded_imgs = autoencoder.decoder(encoded_imgs[:11]).numpy()"
      ],
      "metadata": {
        "id": "40VnVUFEdxQk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "  # display original\n",
        "  ax = plt.subplot(2, n, i + 1)\n",
        "  plt.imshow(np.argmax(flattened_challenges[i], axis=-1), interpolation='nearest', cmap=cmap, norm=norm)\n",
        "  plt.title(\"original\")\n",
        "  #plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  # display reconstruction\n",
        "  ax = plt.subplot(2, n, i + 1 + n)\n",
        "  plt.imshow(np.argmax(decoded_imgs[i], axis=-1), interpolation='nearest', cmap=cmap, norm=norm)\n",
        "  plt.title(\"reconstructed\")\n",
        "  #plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "FIV0tmBEc_H0",
        "outputId": "cd93ac78-9596-4711-f86b-c8f9694d56b8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Move Enconding"
      ],
      "metadata": {
        "id": "jQAcLvAnsU9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_random_move(batch_size):\n",
        "    position_x = np.random.randint(0, 30, (batch_size, 1))\n",
        "    position_y = np.random.randint(0, 30, (batch_size, 1))\n",
        "    n_values = 30\n",
        "    position_x = np.squeeze(np.eye(n_values)[position_x])\n",
        "\n",
        "    n_values = 30\n",
        "    position_y = np.squeeze(np.eye(n_values)[position_y])\n",
        "\n",
        "    move = np.random.randint(0, 10, (batch_size, 1))\n",
        "    n_values = 10\n",
        "    move = np.squeeze(np.eye(n_values)[move])\n",
        "    return move, position_x, position_y"
      ],
      "metadata": {
        "id": "RmLjSVGpsaSe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 5\n",
        "\n",
        "move, position_x, position_y = generate_random_move(batch_size)\n",
        "\n",
        "print(position_x.shape, move.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8idc2woeMYu",
        "outputId": "3dc236ab-af1a-464f-d532-c35db355fc27"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 30) (5, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Do a wrapper and apply using a mapping\n",
        "\n",
        "def apply_move(grid, move, position_x, position_y):\n",
        "    position_x = tf.argmax(position_x, axis=-1)\n",
        "    position_y = tf.argmax(position_y, axis=-1)\n",
        "    grid_modified = tf.identity(grid)\n",
        "    print(grid.dtype, grid_modified.dtype, move.dtype)\n",
        "    move = tf.cast(move, tf.float32)\n",
        "    move = tf.cast(grid_modified, tf.float32)\n",
        "    print(move.shape, grid_modified.shape)\n",
        "    grid_modified = tf.tensor_scatter_nd_update(grid_modified, [position_x, position_y], move)\n",
        "    return grid_modified, move, position_x, position_y\n",
        "\n",
        "def apply_move_wrapper(grid, move, position_x, position_y):\n",
        "    #grid_modified,_, _, _ =\n",
        "    tf.map_fn(lambda x: apply_move(x[0], x[1], x[2], x[3]), (grid, move, position_x, position_y))\n",
        "    return None #grid_modified"
      ],
      "metadata": {
        "id": "-EZ5UaCMgCzH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Function to apply move on a single instance\n",
        "def apply_move(grid, move, position_x, position_y):\n",
        "    position_x = tf.argmax(position_x, axis=-1)\n",
        "    position_y = tf.argmax(position_y, axis=-1)\n",
        "\n",
        "    grid_modified = tf.identity(grid)\n",
        "\n",
        "    move = tf.cast(move, tf.float32)\n",
        "    grid_modified = tf.cast(grid_modified, tf.float32)\n",
        "\n",
        "\n",
        "    # Ensure indices are correctly shaped\n",
        "    indices = tf.stack([[position_x, position_y]], axis=0)  # Shape (1, 2)\n",
        "\n",
        "    # Apply the move\n",
        "    grid_modified = tf.tensor_scatter_nd_update(grid_modified, indices, [move])\n",
        "\n",
        "    return grid_modified, move, position_x, position_y\n",
        "\n",
        "# Wrapper function for batch processing\n",
        "def apply_move_wrapper(grid, move, position_x, position_y):\n",
        "    grid_modified = tf.map_fn(lambda x: apply_move(x[0], x[1], x[2], x[3])[0],\n",
        "                              (grid, move, position_x, position_y), dtype=tf.float32)\n",
        "    return grid_modified\n"
      ],
      "metadata": {
        "id": "_5z4gUVoO3zl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_modified = apply_move_wrapper(flattened_challenges[:batch_size], move, position_x, position_y)"
      ],
      "metadata": {
        "id": "WAd28VJvgzGu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(position_x.shape, move.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2TROocnktco",
        "outputId": "0c7013c0-a161-4e82-86e8-b89b0588aaa1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 30) (5, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    cmap, norm = get_color_map(number_of_categories=9)\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title('input')\n",
        "    plt.imshow(np.argmax(flattened_challenges[i], axis=-1), interpolation='nearest', cmap=cmap, norm=norm)\n",
        "    plt.axis('off')\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title('output')\n",
        "    plt.imshow(np.argmax(grid_modified[i], axis=-1), interpolation='nearest', cmap=cmap, norm=norm)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5fdxS-Y6h0aJ",
        "outputId": "9be87bc4-9aba-4ead-bb1e-bd3c7e3c87f6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAELCAYAAABEYIWnAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAACn9JREFUeJzt3UtoXGUbwPFnnLRKOgaDSaWLJiFVQnUjVOwmsTfaUlqkoHbhpa1U6gV1ZwpaMIVuKiLSRUMV2ujCvfghqIhNCCKIiosWg0WtLqqIeMELtsb323wExmlN9Gs76Ty/36Zk5pwz7yzOw79nziSVUkoJACCtK5q9AACgucQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxMA8NjY2FpVKJb744otmLwWAFiYGmJMTJ07EyMiIMIEWdujQoRgbG7skr2WmzC9iYB6777774rfffove3t5mLyVOnDgR+/btc+JCC7vUMWCmzB9tzV4A51etVqNarTZ7GQC0OFcG5rG/3jPQ19cXW7ZsicnJybj11lvjqquuiv7+/nj55ZfPud/ExEQ8+OCDce2110ZHR0ds3749vv/++7ptK5VKjIyMNLx2X19f7Ny5c+Z4d911V0RErFmzJiqVSlQqlTh27NiFfsvAP/TRRx/Fpk2boqOjI2q1Wqxbty7ee++9medHRkaiUqk07Heu+XL8+PEYHx+fOcdXr15dt62Z0rpcGbjMnDx5Mu68887YtWtX7NixI44cORI7d+6MFStWxE033VS37aOPPhrXXHNNjIyMxNTUVIyOjsapU6fi2LFj5xwO53PbbbfF448/HgcPHownn3wyli9fHhEx8y/QHMePH4+hoaHo6OiI4eHhWLBgQRw+fDhWr14d4+PjsXLlyjkf6/nnn4/HHnssarVaPPXUUxERcd1119VtY6a0LjFwmZmamoqJiYkYGhqKiIht27bF0qVL4+jRo/Hss8/Wbbtw4cJ4++23Y8GCBRER0dvbG8PDw/Haa6/F7bffPufX7O/vj6GhoTh48GCsX79+5n8LQHPt3bs3zp49G5OTk9Hf3x8REdu3b4+BgYEYHh6O8fHxOR9r69atsXfv3ujq6op77733nNuYKa3LxwSXmRtvvHEmBCIiuru7Y2BgID777LOGbXfv3j1z0kZEPPzww9HW1havv/76JVkrcPFMT0/Hm2++GVu3bp0JgYiIJUuWxN133x2Tk5Px008/XdDXNFNalxi4zPT09DQ81tnZ2fC5XUTEDTfcUPdzrVaLJUuWuHsXWsC3334bv/76awwMDDQ8t3z58vjzzz/jq6++uqCvaaa0LjFwmTnftwtKKRf0daanpy/o8YDmON9n+Zf6HDdT5jcx0MI+/fTTup9//vnnOH36dPT19c081tnZGT/88EPddmfOnInTp0/XPfZPbg4CLr7u7u5ob2+Pqamphuc++eSTuOKKK2Lp0qXR2dkZEdFwnp86daphv9nOczOldYmBFvbCCy/E2bNnZ34eHR2NP/74IzZt2jTz2LJly2JiYqJhv79W/KJFiyKicaAAzVGtVmPDhg3x6quv1l2m/+abb+KVV16JwcHB6OjoiGXLlkVE1J3nv/zyS7z00ksNx1y0aNHfnuNmSuvybYIWdubMmVi3bl1s27Ytpqam4tChQzE4OFh31+8DDzwQDz30UNxxxx2xfv36+Pjjj+ONN96Irq6uumPdfPPNUa1W48CBA/Hjjz/GlVdeGWvXro3Fixdf6rcF/M/+/fvjrbfeisHBwXjkkUeira0tDh8+HL///ns888wzERGxYcOG6OnpiV27dsUTTzwR1Wo1jhw5Et3d3fHll1/WHW/FihUxOjoa+/fvj+uvvz4WL14ca9eunXneTGlhhXnr6NGjJSLK559/Xkoppbe3t2zevLlhu1WrVpVVq1Y17Dc+Pl52795dOjs7S61WK/fcc0/57rvv6vadnp4ue/bsKV1dXaW9vb1s3LixnDx5svT29pYdO3bUbfviiy+W/v7+Uq1WS0SUd9555wK/Y+Cf+vDDD8vGjRtLrVYr7e3tZc2aNeXdd9+t2+aDDz4oK1euLAsXLiw9PT3lueeea5gvpZTy9ddfl82bN5err766RMTMXDFTWl+llAt85xlNNzY2Fvfff3+8//77ccsttzR7OcBlzkxpfe4ZAIDkxAAAJCcGACA59wwAQHKuDABAcmIAAJITAwCQ3Jx/A+Fsv0f66aef/teL2Ldv37/eFzK5HG/xMTug+WabHa4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAguTl/tfD/+foPkJfZAfOfKwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhuzl8tnO2vg/n6EHAuZgfMf64MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMlVSillThtWKhd7LcAs5ni6zitmBzTfbLPDlQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDk2pq9AICLoXfPf/72+VMHtlyilcD858oAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSq5RSypw2rFQu9lqAWczxdJ1XzA5ovtlmhysDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyVVKKaXZiwAAmseVAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEjuv1NkomaTMtBKAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv2DLSTMCell(keras.Layer):\n",
        "    def __init__(self, kernel_size, filters, size=(15, 15), **kwargs):\n",
        "        super(Conv2DLSTMCell, self).__init__(**kwargs)\n",
        "        self.height=size[0]\n",
        "        self.width=size[1]\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.conv = layers.Conv2D(filters * 4, kernel_size, padding=\"same\", activation=None)\n",
        "        self.state_size = [tf.TensorShape([self.height, self.width, filters]), tf.TensorShape([self.height, self.width, filters])]\n",
        "        self.h_prev = None\n",
        "        self.c_prev = None\n",
        "\n",
        "    def initialize(self, inputs):\n",
        "        '''\n",
        "        Initialize the hidden cell states H\n",
        "        '''\n",
        "\n",
        "        batch_size, _, _, _ = inputs.shape\n",
        "\n",
        "        self.h_prev = tf.zeros([batch_size, self.height, self.width, self.filters])\n",
        "        self.c_prev = tf.zeros([batch_size, self.height, self.width, self.filters])\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.batch_size, self.height, self.width, _ = input_shape\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, t, training=None):\n",
        "        grid = inputs\n",
        "        if t == 0:\n",
        "            self.initialize(grid)\n",
        "\n",
        "        concat_inputs = tf.concat([grid, self.h_prev], axis=-1)\n",
        "        conv_output = self.conv(concat_inputs)\n",
        "\n",
        "        f, i, o, g = tf.split(conv_output, num_or_size_splits=4, axis=-1)\n",
        "        f = tf.sigmoid(f)\n",
        "        i = tf.sigmoid(i)\n",
        "        o = tf.sigmoid(o)\n",
        "        g = tf.tanh(g)\n",
        "\n",
        "        self.c_next = f * self.c_prev + i * g\n",
        "        outputs = o * tf.tanh(self.c_next)\n",
        "        self.h_next = outputs\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "QawYuXpugGwV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grid Cell Machines"
      ],
      "metadata": {
        "id": "dymuutfyevQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "latent_dim = 256\n",
        "\n",
        "class GridLikeEncoding(Model):\n",
        "    def __init__(self, encoder, batch_size=32):\n",
        "      super(GridLikeEncoding, self).__init__()\n",
        "\n",
        "      self.move_encoding = layers.Dense(32, activation=tf.keras.layers.LeakyReLU())\n",
        "      self.position_encoding = layers.Dense(32, activation=tf.keras.layers.LeakyReLU())\n",
        "      self.pos_move_concat = layers.Concatenate(axis=-1)\n",
        "      self.conv_encoding = layers.Conv2D(128, (3, 3), activation='swish', padding='same', strides=2)\n",
        "\n",
        "\n",
        "      self.conv = layers.Conv2D(32, (3, 3), activation='swish', padding='same', strides=2)\n",
        "      #self.flat = layers.Flatten()\n",
        "      self.visual_1 = layers.Dense(256, activation=tf.keras.layers.LeakyReLU())\n",
        "      self.visual_2 = layers.Dense(128, activation=tf.keras.layers.LeakyReLU())\n",
        "\n",
        "\n",
        "      self.input_concat = layers.Concatenate(axis=-1)\n",
        "      self.input_encoding = layers.Dense(256, activation=tf.keras.layers.LeakyReLU())\n",
        "\n",
        "      self.lstm = Conv2DLSTMCell((3,3), 256)\n",
        "\n",
        "      self.grid_encoder = layers.Dense(512, activation=tf.keras.layers.LeakyReLU())\n",
        "      self.grid_layer = layers.Dense(1024, activation='sigmoid')\n",
        "\n",
        "      self.encoder = encoder\n",
        "      self.encoder.trainable = False\n",
        "\n",
        "      self.nb_moves_train = 10\n",
        "      self.batch_size = batch_size\n",
        "\n",
        "      self.gridlike_encoder = tf.keras.Sequential([\n",
        "        layers.Input(shape=(15, 15, 1024,)),\n",
        "        layers.Dense(1024, activation=tf.keras.layers.LeakyReLU()),\n",
        "        layers.Dropout(0.1),\n",
        "        layers.Dense(1024, activation=tf.keras.layers.LeakyReLU()),\n",
        "        layers.Dense(512, activation=tf.keras.layers.LeakyReLU()),\n",
        "        layers.Dropout(0.1),\n",
        "        layers.Dense(512, activation=tf.keras.layers.LeakyReLU()),\n",
        "        layers.Dense(256, activation=tf.keras.layers.LeakyReLU()),\n",
        "        layers.Dropout(0.1),\n",
        "        layers.Dense(256, activation=tf.keras.layers.LeakyReLU()),\n",
        "        layers.Dense(latent_dim, activation=tf.keras.layers.LeakyReLU()),])\n",
        "\n",
        "\n",
        "    def compile(self, **kwargs):\n",
        "        super().compile(**kwargs)\n",
        "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_tracker,]\n",
        "\n",
        "    def call(self, inputs, t):\n",
        "        move_input, position_x, position_y, visual_input = inputs\n",
        "\n",
        "        move_encoded = self.move_encoding(move_input)\n",
        "        position_encoded_x = self.position_encoding(position_x)\n",
        "        position_encoded_y = self.position_encoding(position_y)\n",
        "        pos_move_encoded = self.pos_move_concat([move_encoded, position_encoded_x, position_encoded_y])\n",
        "        pos_move_encoded = self.conv_encoding(pos_move_encoded)\n",
        "\n",
        "        visual_encoded = self.conv(visual_input)\n",
        "        #visual_encoded = self.flat(visual_encoded)\n",
        "        visual_encoded = self.visual_1(visual_encoded)\n",
        "        visual_encoded = self.visual_2(visual_encoded)\n",
        "\n",
        "        combined_input = self.input_concat([pos_move_encoded, visual_encoded])\n",
        "        input_encoded = self.input_encoding(combined_input)\n",
        "\n",
        "        #input_encoded = tf.squeeze(input_encoded)\n",
        "\n",
        "        lstm_out = self.lstm.call(input_encoded, t=t)\n",
        "\n",
        "        grid_encoded = self.grid_encoder(lstm_out)\n",
        "        grid_out = self.grid_layer(grid_encoded)\n",
        "\n",
        "        latent_representation = self.gridlike_encoder(grid_out)\n",
        "\n",
        "        return latent_representation\n",
        "\n",
        "    def train_step(self, input_grids):\n",
        "\n",
        "        grid_modified = input_grids\n",
        "        moves = []\n",
        "        positions_x = []\n",
        "        positions_y = []\n",
        "        historic = [input_grids, ]\n",
        "\n",
        "        for i in range(self.nb_moves_train):\n",
        "            move, position_x, position_y = generate_random_move(self.batch_size)\n",
        "\n",
        "            grid_modified = apply_move_wrapper(grid_modified, move, position_x, position_y)\n",
        "            historic.append(grid_modified)\n",
        "\n",
        "            move = tf.expand_dims(tf.expand_dims(move, axis=1), axis=1)\n",
        "            move = tf.tile(move, [1, 30, 30, 1])\n",
        "\n",
        "            position_x = tf.expand_dims(tf.expand_dims(position_x, axis=1), axis=1)\n",
        "            position_x = tf.tile(position_x, [1, 30, 30, 1])\n",
        "\n",
        "            position_y = tf.expand_dims(tf.expand_dims(position_y, axis=1), axis=1)\n",
        "            position_y = tf.tile(position_y, [1, 30, 30, 1])\n",
        "\n",
        "            moves.append(move)\n",
        "            positions_x.append(position_x)\n",
        "            positions_y.append(position_y)\n",
        "\n",
        "\n",
        "\n",
        "        ground_truth_encoding = self.encoder(grid_modified)\n",
        "\n",
        "        #moves = np.array(moves)\n",
        "        #positions_x = np.array(positions_x)\n",
        "        #positions_y = np.array(positions_y)\n",
        "\n",
        "\n",
        "        y = input_grids\n",
        "        with tf.GradientTape() as tape:\n",
        "            for i in range(self.nb_moves_train):\n",
        "                visual = historic[i] if random.randint(0, 100) <= 10 else tf.zeros_like(historic[i])\n",
        "                y = self.call([moves[i], positions_x[i], positions_y[i], visual], i)\n",
        "            loss = self.loss(ground_truth_encoding, y)\n",
        "\n",
        "        gradients_model = tape.gradient(loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(gradients_model, self.trainable_weights))\n",
        "\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, input_grids):\n",
        "\n",
        "        grid_modified = input_grids\n",
        "        moves = []\n",
        "        positions_x = []\n",
        "        positions_y = []\n",
        "        historic = [input_grids, ]\n",
        "\n",
        "        for i in range(self.nb_moves_train):\n",
        "            move, position_x, position_y = generate_random_move(self.batch_size)\n",
        "\n",
        "            grid_modified = apply_move_wrapper(grid_modified, move, position_x, position_y)\n",
        "            historic.append(grid_modified)\n",
        "\n",
        "            move = tf.expand_dims(tf.expand_dims(move, axis=1), axis=1)\n",
        "            move = tf.tile(move, [1, 30, 30, 1])\n",
        "\n",
        "            position_x = tf.expand_dims(tf.expand_dims(position_x, axis=1), axis=1)\n",
        "            position_x = tf.tile(position_x, [1, 30, 30, 1])\n",
        "\n",
        "            position_y = tf.expand_dims(tf.expand_dims(position_y, axis=1), axis=1)\n",
        "            position_y = tf.tile(position_y, [1, 30, 30, 1])\n",
        "\n",
        "            moves.append(move)\n",
        "            positions_x.append(position_x)\n",
        "            positions_y.append(position_y)\n",
        "\n",
        "        ground_truth_encoding = self.encoder(grid_modified)\n",
        "\n",
        "        #moves = np.array(moves)\n",
        "        #positions_x = np.array(positions_x)\n",
        "        #positions_y = np.array(positions_y)\n",
        "\n",
        "        y = input_grids\n",
        "        for i in range(self.nb_moves_train):\n",
        "\n",
        "            visual = historic[i] if random.randint(0, 100) <= 10 else tf.zeros_like(historic[i])\n",
        "\n",
        "            y = self.call([moves[i], positions_x[i], positions_y[i], visual], i)\n",
        "        loss = self.loss(ground_truth_encoding, y)\n",
        "\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ],
      "metadata": {
        "id": "GYSlZEgLd0cd"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "gridlike_model = GridLikeEncoding(autoencoder.encoder, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "67LxcQELuXO1"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gridlike_model.compile(optimizer=keras.optimizers.Adam(learning_rate=5e-4), loss=losses.MeanSquaredError())\n",
        "gridlike_model.build([None, flattened_challenges.shape[1], flattened_challenges.shape[2], 10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVj5s2f1y9-O",
        "outputId": "dc16cd14-9b41-44f5-8dbf-cb5eb72996cc"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'grid_like_encoding_2', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "move, position_x, position_y = generate_random_move(5)\n",
        "move = tf.expand_dims(tf.expand_dims(move, axis=1), axis=1)\n",
        "move = tf.tile(move, [1, 30, 30, 1])\n",
        "\n",
        "position_x = tf.expand_dims(tf.expand_dims(position_x, axis=1), axis=1)\n",
        "position_x = tf.tile(position_x, [1, 30, 30, 1])\n",
        "\n",
        "position_y = tf.expand_dims(tf.expand_dims(position_y, axis=1), axis=1)\n",
        "position_y = tf.tile(position_y, [1, 30, 30, 1])\n",
        "\n",
        "tmp_test = gridlike_model.call([move, position_x, position_y, flattened_challenges[:5]], t=0)"
      ],
      "metadata": {
        "id": "3iedKzoVzhxM",
        "outputId": "cb400ee9-fc15-4d41-a2ad-0e0a37828bba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input 0 of layer \"conv_lstm2d\" is incompatible with the layer: expected ndim=5, found ndim=4. Full shape received: (5, 15, 15, 256)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-1039439acf5e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mposition_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtmp_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgridlike_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_challenges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-46-fdd78f7a3500>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, t)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# LSTM Processing with Multiple Skip Connections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mlstm_out1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mlstm_out2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mlstm_out2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_add1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlstm_out1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_out2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_last_axis_squeeze\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    187\u001b[0m                     \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                     \u001b[0;34m\"is incompatible with the layer: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"conv_lstm2d\" is incompatible with the layer: expected ndim=5, found ndim=4. Full shape received: (5, 15, 15, 256)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flattened_challenges.shape"
      ],
      "metadata": {
        "id": "khcpXzYD719H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = gridlike_model.fit(flattened_challenges[:2560],\n",
        "                             epochs=100,\n",
        "                             batch_size=batch_size,\n",
        "                             shuffle=True,\n",
        "                             validation_split=0.2)"
      ],
      "metadata": {
        "id": "J9lU91Mm3Y8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "89D5lUYAsYnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##VISUAL TEST"
      ],
      "metadata": {
        "id": "Hn5gI2_osZbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 5\n",
        "#grid_modified = tf.identity(flattened_challenges[:batch_size])\n",
        "grid_modified = flattened_challenges[:batch_size]\n",
        "moves = []\n",
        "positions_x = []\n",
        "positions_y = []\n",
        "historic = [grid_modified, ]\n",
        "# historic = [tf.identity(grid_modified), ]\n",
        "for i in range(10):\n",
        "    move, position_x, position_y = generate_random_move(batch_size)\n",
        "\n",
        "    grid_modified = apply_move_wrapper(grid_modified, move, position_x, position_y)\n",
        "    #historic.append(tf.identity(grid_modified))\n",
        "    historic.append(grid_modified)\n",
        "\n",
        "    move = tf.expand_dims(tf.expand_dims(move, axis=1), axis=1)\n",
        "    move = tf.tile(move, [1, 30, 30, 1])\n",
        "\n",
        "    position_x = tf.expand_dims(tf.expand_dims(position_x, axis=1), axis=1)\n",
        "    position_x = tf.tile(position_x, [1, 30, 30, 1])\n",
        "\n",
        "    position_y = tf.expand_dims(tf.expand_dims(position_y, axis=1), axis=1)\n",
        "    position_y = tf.tile(position_y, [1, 30, 30, 1])\n",
        "\n",
        "    moves.append(move)\n",
        "    positions_x.append(position_x)\n",
        "    positions_y.append(position_y)\n",
        "\n",
        "    ground_truth_encoding = autoencoder.encoder(grid_modified)\n",
        "    ground_truth_decoding = autoencoder.decoder(ground_truth_encoding)\n",
        "\n",
        "    for i in range(1):\n",
        "        cmap, norm = get_color_map(number_of_categories=9)\n",
        "        plt.title('input')\n",
        "        plt.imshow(np.argmax(ground_truth_decoding[i], axis=-1), interpolation='nearest', cmap=cmap, norm=norm)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "print(\"----------------------------------------------------------------------------\")\n",
        "print(\"############################################################################\")\n",
        "print(\"----------------------------------------------------------------------------\")\n",
        "\n",
        "y = flattened_challenges[:batch_size]\n",
        "for i in range(10):\n",
        "\n",
        "    visual = historic[i] if random.randint(0, 100) <= 10 else tf.zeros_like(historic[i])\n",
        "\n",
        "    y = gridlike_model.call([moves[i], positions_x[i], positions_y[i], visual], i)\n",
        "    predicted_decoding = autoencoder.decoder(y)\n",
        "    for i in range(1):\n",
        "        cmap, norm = get_color_map(number_of_categories=9)\n",
        "        plt.title('output')\n",
        "        plt.imshow(np.argmax(predicted_decoding[i], axis=-1), interpolation='nearest', cmap=cmap, norm=norm)\n",
        "        plt.axis('off')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "a4DrYZs2r_Tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    cmap, norm = get_color_map(number_of_categories=9)\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title('input')\n",
        "    plt.imshow(np.argmax(flattened_challenges[i], axis=-1), interpolation='nearest', cmap=cmap, norm=norm)\n",
        "    plt.axis('off')\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title('output')\n",
        "    plt.imshow(np.argmax(grid_modified[i], axis=-1), interpolation='nearest', cmap=cmap, norm=norm)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "bsja3IA4sgDF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}