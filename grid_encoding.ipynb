{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pumafi/problem_solving_rl_pumafi/blob/main/grid_encoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLBEvBpgYjNo",
        "outputId": "72809df5-a064-4e90-b123-38dcc8ec4da8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'problem_solving_rl_pumafi'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 23 (delta 3), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (23/23), 17.99 MiB | 9.68 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n",
            "/content/problem_solving_rl_pumafi\n"
          ]
        }
      ],
      "source": [
        "RUNNING_IN_COLAB = True\n",
        "\n",
        "%cd /content\n",
        "\n",
        "if RUNNING_IN_COLAB:\n",
        "    REPO_URL = 'https://github.com/Pumafi/problem_solving_rl_pumafi'\n",
        "    BRANCH   = 'main'\n",
        "    REPO_DIR = 'problem_solving_rl_pumafi'\n",
        "\n",
        "    from pathlib import Path\n",
        "\n",
        "    if Path(REPO_DIR).is_dir():\n",
        "      !rm -rf {REPO_DIR}\n",
        "\n",
        "    # Download the repository\n",
        "    if not Path(REPO_DIR).is_dir():\n",
        "        !git clone --branch {BRANCH} --depth=1 -- {REPO_URL} {REPO_DIR}\n",
        "\n",
        "    %cd {REPO_DIR}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "from tqdm.notebook import trange, tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "\n",
        "\n",
        "from scipy.stats import kde\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "wuqLpqehYmQ2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LvOiHKzWiOfe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load code from the repo\n",
        "from utils.data_handling import get_color_map, pad_to_shape, preprocess_challenge_data\n",
        "from utils.preprocess_metalearning_data import filter_and_split_inputs\n",
        "from models.autoencoder import AutoEncoder"
      ],
      "metadata": {
        "id": "XnQHErZ4YmUO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def load_json(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "training_challenges = load_json('./data/arc-agi_training_challenges.json')\n",
        "training_solutions = load_json('./data/arc-agi_training_solutions.json')\n",
        "evaluation_challenges = load_json('./data/arc-agi_evaluation_challenges.json')\n",
        "\n",
        "print(\"Data loaded successfully.\")\n",
        "print(f\"Training tasks: {len(training_challenges)}\")\n",
        "print(f\"Evaluation tasks: {len(evaluation_challenges)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Krvii9ISYmXN",
        "outputId": "58e49c95-c6fa-49a8-d0bb-aedc71e091bb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n",
            "Training tasks: 400\n",
            "Evaluation tasks: 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all inputs for meta learning, then the training data for latter\n",
        "challenge_propositioner_inputs, _, _, _, _ = preprocess_challenge_data(training_challenges, training_solutions)\n",
        "print(len(challenge_propositioner_inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoDrfYxudPi0",
        "outputId": "b62dcdbd-e00b-479d-dbb2-2ee0a159a04b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In order of access we have:\n",
        "#     challenge_propositioner_inputs [problem_nb (list)] [example_nb (list)] [0/1 - input/output (tuple)] -> [30, 30, 10] (ndarray)\n",
        "\n",
        "# Visualize the size of examples sets (NB: All have at least 2 examples, but 2 is to few for my idea)\n",
        "for i in range(5):\n",
        "  print(\"Problem nb \", i +1, \" | nb examples: \", len(challenge_propositioner_inputs[i]))\n",
        "\n",
        "print(\"\\nSize of one grid: \", challenge_propositioner_inputs[0][0][0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv3v5iekYs4N",
        "outputId": "a2e9cee3-9091-46f4-a9b4-36ec76be6352"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem nb  1  | nb examples:  5\n",
            "Problem nb  2  | nb examples:  5\n",
            "Problem nb  3  | nb examples:  3\n",
            "Problem nb  4  | nb examples:  2\n",
            "Problem nb  5  | nb examples:  3\n",
            "\n",
            "Size of one grid:  (30, 30, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flattened_challenges = [\n",
        "    x\n",
        "    for xss in challenge_propositioner_inputs\n",
        "    for xs in xss\n",
        "    for x in xs\n",
        "]\n",
        "\n",
        "flattened_challenges = np.array(flattened_challenges)\n",
        "\n",
        "print(flattened_challenges.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2jDTzmcdYv0",
        "outputId": "e23fac45-7b71-4dd1-cc1d-06e60799e6c1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2604, 30, 30, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cmap, norm = get_color_map(number_of_categories=9)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('input')\n",
        "plt.imshow(np.argmax(challenge_propositioner_inputs[0][0][0], axis=-1), interpolation='nearest', cmap=cmap, norm=norm)\n",
        "plt.axis('off')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('output')\n",
        "plt.imshow(np.argmax(challenge_propositioner_inputs[0][0][1], axis=-1), interpolation='nearest', cmap=cmap, norm=norm)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "_tkp6Um0aUm1",
        "outputId": "8a84e9dc-3a22-4050-9dd6-d2c6e531e309"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NB: for this and place cell, get inspiration from GANs, variational distance for Kozachenko-Leonenko, as well as initializing the ccenter of massesf\n",
        "\n",
        "autoencoder = AutoEncoder()\n",
        "autoencoder.compile(optimizer=keras.optimizers.Adam(learning_rate=5e-4), loss=losses.CategoricalCrossentropy())\n",
        "autoencoder.build([None, flattened_challenges.shape[1], flattened_challenges.shape[2], 10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BmHW-rTctV3",
        "outputId": "576a4e82-6480-4da9-bd05-7440a67b3b7b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'auto_encoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_imgs = autoencoder.encoder(flattened_challenges[:2]).numpy()\n",
        "decoded_imgs = autoencoder.decoder(encoded_imgs[:2]).numpy()"
      ],
      "metadata": {
        "id": "g-DXsr58dphx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.encoder.load_weights(\"weights/weigts-encoder.weights.h5\")\n",
        "autoencoder.decoder.load_weights(\"weights/weigts-decoder.weights.h5\")"
      ],
      "metadata": {
        "id": "k8vo9qQxdiO8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_imgs = autoencoder.encoder(flattened_challenges[:11]).numpy()\n",
        "decoded_imgs = autoencoder.decoder(encoded_imgs[:11]).numpy()"
      ],
      "metadata": {
        "id": "40VnVUFEdxQk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "  # display original\n",
        "  ax = plt.subplot(2, n, i + 1)\n",
        "  plt.imshow(np.argmax(flattened_challenges[i], axis=-1), interpolation='nearest', cmap=cmap, norm=norm)\n",
        "  plt.title(\"original\")\n",
        "  #plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  # display reconstruction\n",
        "  ax = plt.subplot(2, n, i + 1 + n)\n",
        "  plt.imshow(np.argmax(decoded_imgs[i], axis=-1), interpolation='nearest', cmap=cmap, norm=norm)\n",
        "  plt.title(\"reconstructed\")\n",
        "  #plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "FIV0tmBEc_H0",
        "outputId": "88fc2b75-9e6c-4688-901f-339f1dc43fd9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Move Enconding"
      ],
      "metadata": {
        "id": "jQAcLvAnsU9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_random_move(batch_size):\n",
        "    position_x = np.random.randint(0, 30, (batch_size, 1))\n",
        "    position_y = np.random.randint(0, 30, (batch_size, 1))\n",
        "    n_values = 30\n",
        "    position_x = np.squeeze(np.eye(n_values)[position_x])\n",
        "\n",
        "    n_values = 30\n",
        "    position_y = np.squeeze(np.eye(n_values)[position_y])\n",
        "\n",
        "    move = np.random.randint(0, 10, (batch_size, 1))\n",
        "    n_values = 10\n",
        "    move = np.squeeze(np.eye(n_values)[move])\n",
        "    return move, position_x, position_y"
      ],
      "metadata": {
        "id": "RmLjSVGpsaSe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 5\n",
        "\n",
        "move, position_x, position_y = generate_random_move(batch_size)\n",
        "\n",
        "print(position_x.shape, move.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8idc2woeMYu",
        "outputId": "5584d934-63ed-47d8-99e1-0fa2cefa1553"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 30) (5, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Do a wrapper and apply using a mapping\n",
        "\n",
        "def apply_move(grid, move, position_x, position_y):\n",
        "    position_x = tf.argmax(position_x, axis=-1)\n",
        "    position_y = tf.argmax(position_y, axis=-1)\n",
        "    grid_modified = tf.identity(grid)\n",
        "    print(grid.dtype, grid_modified.dtype, move.dtype)\n",
        "    move = tf.cast(move, tf.float32)\n",
        "    move = tf.cast(grid_modified, tf.float32)\n",
        "    print(move.shape, grid_modified.shape)\n",
        "    grid_modified = tf.tensor_scatter_nd_update(grid_modified, [position_x, position_y], move)\n",
        "    return grid_modified, move, position_x, position_y\n",
        "\n",
        "def apply_move_wrapper(grid, move, position_x, position_y):\n",
        "    #grid_modified,_, _, _ =\n",
        "    tf.map_fn(lambda x: apply_move(x[0], x[1], x[2], x[3]), (grid, move, position_x, position_y))\n",
        "    return None #grid_modified"
      ],
      "metadata": {
        "id": "-EZ5UaCMgCzH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Function to apply move on a single instance\n",
        "def apply_move(grid, move, position_x, position_y):\n",
        "    position_x = tf.argmax(position_x, axis=-1)\n",
        "    position_y = tf.argmax(position_y, axis=-1)\n",
        "\n",
        "    grid_modified = tf.identity(grid)\n",
        "\n",
        "    move = tf.cast(move, tf.float32)\n",
        "    grid_modified = tf.cast(grid_modified, tf.float32)\n",
        "\n",
        "\n",
        "    # Ensure indices are correctly shaped\n",
        "    indices = tf.stack([[position_x, position_y]], axis=0)  # Shape (1, 2)\n",
        "\n",
        "    # Apply the move\n",
        "    grid_modified = tf.tensor_scatter_nd_update(grid_modified, indices, [move])\n",
        "\n",
        "    return grid_modified, move, position_x, position_y\n",
        "\n",
        "# Wrapper function for batch processing\n",
        "def apply_move_wrapper(grid, move, position_x, position_y):\n",
        "    grid_modified = tf.map_fn(lambda x: apply_move(x[0], x[1], x[2], x[3])[0],\n",
        "                              (grid, move, position_x, position_y), dtype=tf.float32)\n",
        "    return grid_modified\n"
      ],
      "metadata": {
        "id": "_5z4gUVoO3zl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_modified = apply_move_wrapper(flattened_challenges[:batch_size], move, position_x, position_y)"
      ],
      "metadata": {
        "id": "WAd28VJvgzGu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(position_x.shape, move.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2TROocnktco",
        "outputId": "2a3e128a-ab18-4ddc-adcf-69779fc32612"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 30) (5, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    cmap, norm = get_color_map(number_of_categories=9)\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title('input')\n",
        "    plt.imshow(np.argmax(flattened_challenges[i], axis=-1), interpolation='nearest', cmap=cmap, norm=norm)\n",
        "    plt.axis('off')\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title('output')\n",
        "    plt.imshow(np.argmax(grid_modified[i], axis=-1), interpolation='nearest', cmap=cmap, norm=norm)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5fdxS-Y6h0aJ",
        "outputId": "01d504fa-32e7-4ebd-e3dd-7784186518e7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv2DLSTMCell(keras.Layer):\n",
        "    def __init__(self, kernel_size, filters, size=(15, 15), **kwargs):\n",
        "        super(Conv2DLSTMCell, self).__init__(**kwargs)\n",
        "        self.height=size[0]\n",
        "        self.width=size[1]\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.conv = layers.Conv2D(filters * 4, kernel_size, padding=\"same\", activation=None)\n",
        "        self.state_size = [tf.TensorShape([self.height, self.width, filters]), tf.TensorShape([self.height, self.width, filters])]\n",
        "        self.h_prev = None\n",
        "        self.c_prev = None\n",
        "\n",
        "    def initialize(self, inputs):\n",
        "        '''\n",
        "        Initialize the hidden cell states H\n",
        "        '''\n",
        "\n",
        "        batch_size, _, _, _ = inputs.shape\n",
        "\n",
        "        self.h_prev = tf.zeros([batch_size, self.height, self.width, self.filters])\n",
        "        self.c_prev = tf.zeros([batch_size, self.height, self.width, self.filters])\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.batch_size, self.height, self.width, _ = input_shape\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, t, training=None):\n",
        "        grid = inputs\n",
        "        if t == 0:\n",
        "            self.initialize(grid)\n",
        "\n",
        "        concat_inputs = tf.concat([grid, self.h_prev], axis=-1)\n",
        "        conv_output = self.conv(concat_inputs)\n",
        "\n",
        "        f, i, o, g = tf.split(conv_output, num_or_size_splits=4, axis=-1)\n",
        "        f = tf.sigmoid(f)\n",
        "        i = tf.sigmoid(i)\n",
        "        o = tf.sigmoid(o)\n",
        "        g = tf.tanh(g)\n",
        "\n",
        "        self.c_next = f * self.c_prev + i * g\n",
        "        outputs = o * tf.tanh(self.c_next)\n",
        "        self.h_next = outputs\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "QawYuXpugGwV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grid Cell Machines"
      ],
      "metadata": {
        "id": "dymuutfyevQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "latent_dim = 256\n",
        "\n",
        "class GridLikeEncoding(Model):\n",
        "    def __init__(self, encoder, batch_size=32):\n",
        "      super(GridLikeEncoding, self).__init__()\n",
        "\n",
        "      self.move_encoding = layers.Dense(32, activation=tf.keras.layers.LeakyReLU())\n",
        "      self.position_encoding = layers.Dense(32, activation=tf.keras.layers.LeakyReLU())\n",
        "      self.pos_move_concat = layers.Concatenate(axis=-1)\n",
        "      self.conv_encoding = layers.Conv2D(128, (3, 3), activation='swish', padding='same', strides=2)\n",
        "\n",
        "\n",
        "      self.conv = layers.Conv2D(32, (3, 3), activation='swish', padding='same', strides=2)\n",
        "      #self.flat = layers.Flatten()\n",
        "      self.visual_1 = layers.Dense(256, activation=tf.keras.layers.LeakyReLU())\n",
        "      self.visual_2 = layers.Dense(128, activation=tf.keras.layers.LeakyReLU())\n",
        "\n",
        "\n",
        "      self.input_concat = layers.Concatenate(axis=-1)\n",
        "      self.input_encoding = layers.Dense(256, activation=tf.keras.layers.LeakyReLU())\n",
        "\n",
        "      self.lstm = Conv2DLSTMCell((3,3), 256)\n",
        "\n",
        "      self.grid_encoder = layers.Dense(512, activation=tf.keras.layers.LeakyReLU())\n",
        "      self.grid_layer = layers.Dense(1024, activation='sigmoid')\n",
        "\n",
        "      self.encoder = encoder\n",
        "      self.encoder.trainable = False\n",
        "\n",
        "      self.nb_moves_train = 10\n",
        "      self.batch_size = batch_size\n",
        "\n",
        "      self.gridlike_encoder = tf.keras.Sequential([\n",
        "        layers.Input(shape=(15, 15, 1024,)),\n",
        "        layers.Dense(1024, activation=tf.keras.layers.LeakyReLU()),\n",
        "        layers.Dropout(0.1),\n",
        "        layers.Dense(1024, activation=tf.keras.layers.LeakyReLU()),\n",
        "        layers.Dense(512, activation=tf.keras.layers.LeakyReLU()),\n",
        "        layers.Dropout(0.1),\n",
        "        layers.Dense(512, activation=tf.keras.layers.LeakyReLU()),\n",
        "        layers.Dense(256, activation=tf.keras.layers.LeakyReLU()),\n",
        "        layers.Dropout(0.1),\n",
        "        layers.Dense(256, activation=tf.keras.layers.LeakyReLU()),\n",
        "        layers.Dense(latent_dim, activation=tf.keras.layers.LeakyReLU()),])\n",
        "\n",
        "\n",
        "    def compile(self, **kwargs):\n",
        "        super().compile(**kwargs)\n",
        "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_tracker,]\n",
        "\n",
        "    def call(self, inputs, t):\n",
        "        move_input, position_x, position_y, visual_input = inputs\n",
        "\n",
        "        move_encoded = self.move_encoding(move_input)\n",
        "        position_encoded_x = self.position_encoding(position_x)\n",
        "        position_encoded_y = self.position_encoding(position_y)\n",
        "        pos_move_encoded = self.pos_move_concat([move_encoded, position_encoded_x, position_encoded_y])\n",
        "        pos_move_encoded = self.conv_encoding(pos_move_encoded)\n",
        "\n",
        "        visual_encoded = self.conv(visual_input)\n",
        "        #visual_encoded = self.flat(visual_encoded)\n",
        "        visual_encoded = self.visual_1(visual_encoded)\n",
        "        visual_encoded = self.visual_2(visual_encoded)\n",
        "\n",
        "        combined_input = self.input_concat([pos_move_encoded, visual_encoded])\n",
        "        input_encoded = self.input_encoding(combined_input)\n",
        "\n",
        "        #input_encoded = tf.squeeze(input_encoded)\n",
        "\n",
        "        lstm_out = self.lstm.call(input_encoded, t=t)\n",
        "\n",
        "        grid_encoded = self.grid_encoder(lstm_out)\n",
        "        grid_out = self.grid_layer(grid_encoded)\n",
        "\n",
        "        latent_representation = self.gridlike_encoder(grid_out)\n",
        "\n",
        "        return latent_representation\n",
        "\n",
        "    def train_step(self, input_grids):\n",
        "\n",
        "        grid_modified = input_grids\n",
        "        moves = []\n",
        "        positions_x = []\n",
        "        positions_y = []\n",
        "        historic = [input_grids, ]\n",
        "\n",
        "        for i in range(self.nb_moves_train):\n",
        "            move, position_x, position_y = generate_random_move(self.batch_size)\n",
        "\n",
        "            grid_modified = apply_move_wrapper(grid_modified, move, position_x, position_y)\n",
        "            historic.append(grid_modified)\n",
        "\n",
        "            move = tf.expand_dims(tf.expand_dims(move, axis=1), axis=1)\n",
        "            move = tf.tile(move, [1, 30, 30, 1])\n",
        "\n",
        "            position_x = tf.expand_dims(tf.expand_dims(position_x, axis=1), axis=1)\n",
        "            position_x = tf.tile(position_x, [1, 30, 30, 1])\n",
        "\n",
        "            position_y = tf.expand_dims(tf.expand_dims(position_y, axis=1), axis=1)\n",
        "            position_y = tf.tile(position_y, [1, 30, 30, 1])\n",
        "\n",
        "            moves.append(move)\n",
        "            positions_x.append(position_x)\n",
        "            positions_y.append(position_y)\n",
        "\n",
        "\n",
        "\n",
        "        ground_truth_encoding = self.encoder(grid_modified)\n",
        "\n",
        "        #moves = np.array(moves)\n",
        "        #positions_x = np.array(positions_x)\n",
        "        #positions_y = np.array(positions_y)\n",
        "\n",
        "\n",
        "        y = input_grids\n",
        "        with tf.GradientTape() as tape:\n",
        "            for i in range(self.nb_moves_train):\n",
        "                visual = historic[i] if random.randint(0, 100) <= 10 else tf.zeros_like(historic[i])\n",
        "                y = self.call([moves[i], positions_x[i], positions_y[i], visual], i)\n",
        "            loss = self.loss(ground_truth_encoding, y)\n",
        "\n",
        "        gradients_model = tape.gradient(loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(gradients_model, self.trainable_weights))\n",
        "\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, input_grids):\n",
        "\n",
        "        grid_modified = input_grids\n",
        "        moves = []\n",
        "        positions_x = []\n",
        "        positions_y = []\n",
        "        historic = [input_grids, ]\n",
        "\n",
        "        for i in range(self.nb_moves_train):\n",
        "            move, position_x, position_y = generate_random_move(self.batch_size)\n",
        "\n",
        "            grid_modified = apply_move_wrapper(grid_modified, move, position_x, position_y)\n",
        "            historic.append(grid_modified)\n",
        "\n",
        "            move = tf.expand_dims(tf.expand_dims(move, axis=1), axis=1)\n",
        "            move = tf.tile(move, [1, 30, 30, 1])\n",
        "\n",
        "            position_x = tf.expand_dims(tf.expand_dims(position_x, axis=1), axis=1)\n",
        "            position_x = tf.tile(position_x, [1, 30, 30, 1])\n",
        "\n",
        "            position_y = tf.expand_dims(tf.expand_dims(position_y, axis=1), axis=1)\n",
        "            position_y = tf.tile(position_y, [1, 30, 30, 1])\n",
        "\n",
        "            moves.append(move)\n",
        "            positions_x.append(position_x)\n",
        "            positions_y.append(position_y)\n",
        "\n",
        "        ground_truth_encoding = self.encoder(grid_modified)\n",
        "\n",
        "        #moves = np.array(moves)\n",
        "        #positions_x = np.array(positions_x)\n",
        "        #positions_y = np.array(positions_y)\n",
        "\n",
        "        y = input_grids\n",
        "        for i in range(self.nb_moves_train):\n",
        "\n",
        "            visual = historic[i] if random.randint(0, 100) <= 10 else tf.zeros_like(historic[i])\n",
        "\n",
        "            y = self.call([moves[i], positions_x[i], positions_y[i], visual], i)\n",
        "        loss = self.loss(ground_truth_encoding, y)\n",
        "\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ],
      "metadata": {
        "id": "GYSlZEgLd0cd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "gridlike_model = GridLikeEncoding(autoencoder.encoder, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "67LxcQELuXO1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gridlike_model.compile(optimizer=keras.optimizers.Adam(learning_rate=5e-4), loss=losses.MeanSquaredError())\n",
        "gridlike_model.build([None, flattened_challenges.shape[1], flattened_challenges.shape[2], 10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVj5s2f1y9-O",
        "outputId": "d6f06ad3-5da4-4e6d-899c-737fc3d5ef80"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'grid_like_encoding', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "move, position_x, position_y = generate_random_move(5)\n",
        "move = tf.expand_dims(tf.expand_dims(move, axis=1), axis=1)\n",
        "move = tf.tile(move, [1, 30, 30, 1])\n",
        "\n",
        "position_x = tf.expand_dims(tf.expand_dims(position_x, axis=1), axis=1)\n",
        "position_x = tf.tile(position_x, [1, 30, 30, 1])\n",
        "\n",
        "position_y = tf.expand_dims(tf.expand_dims(position_y, axis=1), axis=1)\n",
        "position_y = tf.tile(position_y, [1, 30, 30, 1])\n",
        "\n",
        "tmp_test = gridlike_model.call([move, position_x, position_y, flattened_challenges[:5]], t=0)"
      ],
      "metadata": {
        "id": "3iedKzoVzhxM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flattened_challenges.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khcpXzYD719H",
        "outputId": "81ab3656-7780-42d0-da7e-c2a6c7db84af"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2604, 30, 30, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = gridlike_model.fit(flattened_challenges[:2560],\n",
        "                             epochs=100,\n",
        "                             batch_size=batch_size,\n",
        "                             shuffle=True,\n",
        "                             validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J9lU91Mm3Y8E",
        "outputId": "0fd5b396-c034-4b27-e9f3-f6a66599f505"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/deprecation.py:660: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 266ms/step - loss: 0.0708 - val_loss: 0.0250\n",
            "Epoch 2/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 153ms/step - loss: 0.0261 - val_loss: 0.0145\n",
            "Epoch 3/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 155ms/step - loss: 0.0183 - val_loss: 0.0122\n",
            "Epoch 4/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - loss: 0.0142 - val_loss: 0.0109\n",
            "Epoch 5/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 160ms/step - loss: 0.0126 - val_loss: 0.0098\n",
            "Epoch 6/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 173ms/step - loss: 0.0121 - val_loss: 0.0087\n",
            "Epoch 7/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 176ms/step - loss: 0.0101 - val_loss: 0.0081\n",
            "Epoch 8/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 176ms/step - loss: 0.0093 - val_loss: 0.0082\n",
            "Epoch 9/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 173ms/step - loss: 0.0091 - val_loss: 0.0071\n",
            "Epoch 10/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 173ms/step - loss: 0.0086 - val_loss: 0.0069\n",
            "Epoch 11/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 169ms/step - loss: 0.0081 - val_loss: 0.0064\n",
            "Epoch 12/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 164ms/step - loss: 0.0076 - val_loss: 0.0061\n",
            "Epoch 13/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 176ms/step - loss: 0.0080 - val_loss: 0.0055\n",
            "Epoch 14/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 162ms/step - loss: 0.0066 - val_loss: 0.0048\n",
            "Epoch 15/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0051 - val_loss: 0.0046\n",
            "Epoch 16/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 173ms/step - loss: 0.0050 - val_loss: 0.0039\n",
            "Epoch 17/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 166ms/step - loss: 0.0047 - val_loss: 0.0035\n",
            "Epoch 18/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 168ms/step - loss: 0.0043 - val_loss: 0.0033\n",
            "Epoch 19/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 168ms/step - loss: 0.0037 - val_loss: 0.0120\n",
            "Epoch 20/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 177ms/step - loss: 0.0114 - val_loss: 0.0035\n",
            "Epoch 21/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 162ms/step - loss: 0.0039 - val_loss: 0.0030\n",
            "Epoch 22/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 165ms/step - loss: 0.0033 - val_loss: 0.0027\n",
            "Epoch 23/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 170ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 24/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 173ms/step - loss: 0.0032 - val_loss: 0.0025\n",
            "Epoch 25/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 173ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 26/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 167ms/step - loss: 0.0024 - val_loss: 0.0025\n",
            "Epoch 27/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 172ms/step - loss: 0.0025 - val_loss: 0.0022\n",
            "Epoch 28/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 163ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 29/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0022 - val_loss: 0.0020\n",
            "Epoch 30/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 163ms/step - loss: 0.0021 - val_loss: 0.0024\n",
            "Epoch 31/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 174ms/step - loss: 0.0022 - val_loss: 0.0020\n",
            "Epoch 32/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 172ms/step - loss: 0.0019 - val_loss: 0.0068\n",
            "Epoch 33/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 164ms/step - loss: 0.0768 - val_loss: 0.0257\n",
            "Epoch 34/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 172ms/step - loss: 0.0267 - val_loss: 0.0154\n",
            "Epoch 35/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 174ms/step - loss: 0.0184 - val_loss: 0.0125\n",
            "Epoch 36/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 167ms/step - loss: 0.0150 - val_loss: 0.0109\n",
            "Epoch 37/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 166ms/step - loss: 0.0131 - val_loss: 0.0114\n",
            "Epoch 38/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 165ms/step - loss: 0.0121 - val_loss: 0.0096\n",
            "Epoch 39/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 175ms/step - loss: 0.0118 - val_loss: 0.0119\n",
            "Epoch 40/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 166ms/step - loss: 0.0120 - val_loss: 0.0092\n",
            "Epoch 41/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 178ms/step - loss: 0.0113 - val_loss: 0.0083\n",
            "Epoch 42/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - loss: 0.0100 - val_loss: 0.0085\n",
            "Epoch 43/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 174ms/step - loss: 0.0100 - val_loss: 0.0076\n",
            "Epoch 44/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 160ms/step - loss: 0.0095 - val_loss: 0.0074\n",
            "Epoch 45/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 173ms/step - loss: 0.0090 - val_loss: 0.0072\n",
            "Epoch 46/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 179ms/step - loss: 0.0087 - val_loss: 0.0070\n",
            "Epoch 47/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 181ms/step - loss: 0.0087 - val_loss: 0.0070\n",
            "Epoch 48/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 162ms/step - loss: 0.0080 - val_loss: 0.0066\n",
            "Epoch 49/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 162ms/step - loss: 0.0095 - val_loss: 0.0070\n",
            "Epoch 50/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 167ms/step - loss: 0.0080 - val_loss: 0.0064\n",
            "Epoch 51/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 168ms/step - loss: 0.0080 - val_loss: 0.0061\n",
            "Epoch 52/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 174ms/step - loss: 0.0071 - val_loss: 0.0062\n",
            "Epoch 53/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 173ms/step - loss: 0.0070 - val_loss: 0.0057\n",
            "Epoch 54/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 177ms/step - loss: 0.0065 - val_loss: 0.0052\n",
            "Epoch 55/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 178ms/step - loss: 0.0062 - val_loss: 0.0051\n",
            "Epoch 56/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0066 - val_loss: 0.0047\n",
            "Epoch 57/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 173ms/step - loss: 0.0056 - val_loss: 0.0046\n",
            "Epoch 58/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 164ms/step - loss: 0.0051 - val_loss: 0.0043\n",
            "Epoch 59/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - loss: 0.0046 - val_loss: 0.0043\n",
            "Epoch 60/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 173ms/step - loss: 0.0047 - val_loss: 0.0037\n",
            "Epoch 61/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 169ms/step - loss: 0.0041 - val_loss: 0.0035\n",
            "Epoch 62/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 167ms/step - loss: 0.0039 - val_loss: 0.0031\n",
            "Epoch 63/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - loss: 0.0033 - val_loss: 0.0027\n",
            "Epoch 64/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 171ms/step - loss: 0.0030 - val_loss: 0.0027\n",
            "Epoch 65/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 173ms/step - loss: 0.0031 - val_loss: 0.0026\n",
            "Epoch 66/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 177ms/step - loss: 0.0032 - val_loss: 0.0024\n",
            "Epoch 67/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 167ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 68/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 178ms/step - loss: 0.0025 - val_loss: 0.0022\n",
            "Epoch 69/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 171ms/step - loss: 0.0025 - val_loss: 0.0021\n",
            "Epoch 70/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 174ms/step - loss: 0.0022 - val_loss: 0.0021\n",
            "Epoch 71/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 172ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 72/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 166ms/step - loss: 0.0022 - val_loss: 0.0026\n",
            "Epoch 73/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 168ms/step - loss: 0.0022 - val_loss: 0.0019\n",
            "Epoch 74/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 179ms/step - loss: 0.0019 - val_loss: 0.0022\n",
            "Epoch 75/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 172ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 76/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 164ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 77/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 167ms/step - loss: 0.0020 - val_loss: 0.0018\n",
            "Epoch 78/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 168ms/step - loss: 0.0017 - val_loss: 0.0022\n",
            "Epoch 79/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 178ms/step - loss: 0.0023 - val_loss: 0.0019\n",
            "Epoch 80/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 171ms/step - loss: 0.0016 - val_loss: 0.0017\n",
            "Epoch 81/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 173ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 82/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 168ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 83/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 172ms/step - loss: 0.0015 - val_loss: 0.0015\n",
            "Epoch 84/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 164ms/step - loss: 0.0015 - val_loss: 0.0015\n",
            "Epoch 85/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 171ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 86/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 176ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 87/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 173ms/step - loss: 0.0015 - val_loss: 0.0016\n",
            "Epoch 88/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 171ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 89/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - loss: 0.0013 - val_loss: 0.0014\n",
            "Epoch 90/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 173ms/step - loss: 0.0013 - val_loss: 0.0014\n",
            "Epoch 91/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0013 - val_loss: 0.0014\n",
            "Epoch 92/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 173ms/step - loss: 0.0013 - val_loss: 0.0014\n",
            "Epoch 93/100\n",
            "\u001b[1m48/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0013"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-27-0d859c2e401d>\", line 1, in <cell line: 0>\n",
            "    history = gridlike_model.fit(flattened_challenges[:2560],\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n",
            "    logs = self.train_function(iterator)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n",
            "    if not opt_outputs.has_value():\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/optional_ops.py\", line 176, in has_value\n",
            "    return gen_optional_ops.optional_has_value(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_optional_ops.py\", line 172, in optional_has_value\n",
            "    _result = pywrap_tfe.TFE_Py_FastPathExecute(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1684, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "               ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 948, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 994, in getmodule\n",
            "    f = getabsfile(module)\n",
            "        ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 963, in getabsfile\n",
            "    _filename = getsourcefile(object) or getfile(object)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 942, in getsourcefile\n",
            "    elif any(filename.endswith(s) for s in\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 942, in <genexpr>\n",
            "    elif any(filename.endswith(s) for s in\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-0d859c2e401d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = gridlike_model.fit(flattened_challenges[:2560],\n\u001b[0m\u001b[1;32m      2\u001b[0m                              \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/optional_ops.py\u001b[0m in \u001b[0;36mhas_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m       return gen_optional_ops.optional_has_value(\n\u001b[0m\u001b[1;32m    177\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_optional_ops.py\u001b[0m in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    173\u001b[0m         _ctx, \"OptionalHasValue\", name, optional)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    }
  ]
}