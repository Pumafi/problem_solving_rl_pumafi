{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pumafi/problem_solving_rl_pumafi/blob/main/initial_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW0dfyb4k2Xg"
      },
      "source": [
        "## ARC-AGI\n",
        "\n",
        "Ferdinand Bhavsar\n",
        "\n",
        "PhD student, Mines Paris"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RUNNING_IN_COLAB = True\n",
        "\n",
        "if RUNNING_IN_COLAB:\n",
        "    # Uses a private Auth Token, giving read and write access to repo\n",
        "    # TO DELETE IF REPO GOES PUBLIC\n",
        "    REPO_URL = 'https://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@github.com/Pumafi/flumy-wgan-mines'\n",
        "    BRANCH   = 'main'\n",
        "    REPO_DIR = 'flumy-wgan-mines'\n",
        "\n",
        "    from pathlib import Path\n",
        "\n",
        "    %cd /content\n",
        "\n",
        "    if Path(REPO_DIR).is_dir():\n",
        "      !rm -rf {REPO_DIR}\n",
        "\n",
        "    # Download the repository\n",
        "    if not Path(REPO_DIR).is_dir():\n",
        "        !git clone --branch {BRANCH} --depth=1 -- {REPO_URL} {REPO_DIR}\n",
        "\n",
        "    %cd {REPO_DIR}\n",
        "/content"
      ],
      "metadata": {
        "id": "bAMPTlvTrU5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVi2EfE3k2Xk"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1JVLK7tNqDU"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "from tqdm.notebook import trange, tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "\n",
        "\n",
        "from scipy.stats import kde\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "EeVRPcGGk2Xm"
      },
      "source": [
        "### Utilities\n",
        "\n",
        "Get color map (took from some random code I had lying around, so the colors are not the ones from ARC-AGI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbBq_Ee5N5wS"
      },
      "outputs": [],
      "source": [
        "def get_color_map(number_of_categories=4):\n",
        "    \"\"\"\n",
        "    Get the matplotlib colormap and norm for images visualisation\n",
        "    Args:\n",
        "        number_of_categories: number of facies in the slice\n",
        "\n",
        "    Returns: cmap, norm\n",
        "\n",
        "    \"\"\"\n",
        "    if number_of_categories == 4:\n",
        "        cmap = colors.ListedColormap([\"#FF8000\", \"#CBCB33\", \"#9898E5\", \"#66CB33\"])\n",
        "        bounds = [-0.1, 0.9, 1.9, 2.9, 3.9]\n",
        "    elif number_of_categories == 5:\n",
        "        cmap = colors.ListedColormap([\"#000000\", \"#5387AD\", \"#7DD57E\", \"#F1E33E\", \"#C70000\"])\n",
        "        bounds = [-0.1, 0.9, 1.9, 2.9, 3.9, 4.9]\n",
        "    else:  # 9\n",
        "        cmap = colors.ListedColormap(\n",
        "            [\"#000000\", \"#294255\", \"#5387AD\", \"#6DB6B1\", \"#7DD57E\", \"#B5DF5D\", \"#F1E33E\", \"#F77420\", \"#C70000\"])\n",
        "        bounds = [-0.1, 0.9, 1.9, 2.9, 3.9, 4.9, 5.9, 6.9, 7.9, 8.9]\n",
        "\n",
        "    norm = colors.BoundaryNorm(bounds, cmap.N)\n",
        "\n",
        "    return cmap, norm\n",
        "\n",
        "cmap, norm = get_color_map(number_of_categories=9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HM5y6ILLWGxJ",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "0ubkpW-eWCTp",
        "outputId": "8e8b18ac-1dd8-4a6d-e5d1-3202b1703e77"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './arc-agi_training_challenges.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-593fac50c6e7>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtraining_challenges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./arc-agi_training_challenges.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtraining_solutions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./arc-agi_training_solutions.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mevaluation_challenges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./arc-agi_evaluation_challenges.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-593fac50c6e7>\u001b[0m in \u001b[0;36mload_json\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './arc-agi_training_challenges.json'"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "def load_json(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "training_challenges = load_json('./data/arc-agi_training_challenges.json')\n",
        "training_solutions = load_json('./data/arc-agi_training_solutions.json')\n",
        "evaluation_challenges = load_json('./data/arc-agi_evaluation_challenges.json')\n",
        "\n",
        "print(\"Data loaded successfully.\")\n",
        "print(f\"Training tasks: {len(training_challenges)}\")\n",
        "print(f\"Evaluation tasks: {len(evaluation_challenges)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPUDgGJPAr88"
      },
      "outputs": [],
      "source": [
        "def pad_to_shape(arr, target_shape=(30,30,1)):\n",
        "    \"\"\"\n",
        "    Padding the inputs to a single shape, this will make it easier to manipulate\n",
        "    \"\"\"\n",
        "    paddings = [(0, target_shape[i] - arr.shape[i]) for i in range(len(arr.shape))]\n",
        "\n",
        "    padded_array = tf.pad(\n",
        "        arr, paddings, mode='CONSTANT', constant_values=0\n",
        "    )\n",
        "\n",
        "    return padded_array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmsDrKYHk2Xp"
      },
      "source": [
        "Preprocess the challenge data (I'm not touching the indentation, it was a nightmare of using jupyter AND colab for some tests)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hPfc4jOIlR2"
      },
      "outputs": [],
      "source": [
        "def preprocess_challenge_data(challenge_data, solution_data):\n",
        "  challenge_ids = []\n",
        "\n",
        "  # tuples (test_input, test_output) that are both inputs to solution propositioner\n",
        "  challenge_propositioner_inputs = []\n",
        "\n",
        "  # solver trainining input (might be useful)\n",
        "  train_solver_inputs = []\n",
        "  train_solver_outputs = []\n",
        "\n",
        "  #solver test inputs (what the solver will train, getting also a solution as input)\n",
        "  test_solver_inputs = []\n",
        "  test_solver_outputs = []\n",
        "\n",
        "  for id, challenge in challenge_data.items():\n",
        "    challenge_ids.append(id)\n",
        "\n",
        "    # TRAIN\n",
        "    current_challenge_propositioner_inputs = []\n",
        "    current_train_solver_inputs = []\n",
        "    current_train_solver_outputs = []\n",
        "\n",
        "    for train in challenge['train']:\n",
        "      # input\n",
        "      array = np.array(train['input'])\n",
        "\n",
        "      if array.shape[-1] == 1:\n",
        "        # Necessary or to_categorical will mess up the last dim\n",
        "        array = np.expand_dims(array, axis=-1)\n",
        "      array = pad_to_shape(array)\n",
        "      input_cat_tensor = tf.keras.utils.to_categorical(array, num_classes=10)\n",
        "      current_train_solver_inputs.append(input_cat_tensor)\n",
        "\n",
        "      # output\n",
        "      array = np.array(train['output'])\n",
        "\n",
        "      if array.shape[-1] == 1:\n",
        "        array = np.expand_dims(array, axis=-1)\n",
        "      array = pad_to_shape(array)\n",
        "      output_cat_tensor = tf.keras.utils.to_categorical(array, num_classes=10)\n",
        "      current_train_solver_outputs.append(output_cat_tensor)\n",
        "\n",
        "      current_challenge_propositioner_inputs.append((input_cat_tensor, output_cat_tensor))\n",
        "\n",
        "    challenge_propositioner_inputs.append(current_challenge_propositioner_inputs)\n",
        "    train_solver_inputs.append(current_train_solver_inputs)\n",
        "    train_solver_outputs.append(current_train_solver_outputs)\n",
        "\n",
        "    # test\n",
        "    current_test_solver_inputs = []\n",
        "    current_test_solver_outputs = []\n",
        "    for i, test in enumerate(challenge['test']):\n",
        "      # TEST INPUTS\n",
        "      array = np.array(test['input'])\n",
        "\n",
        "      if array.shape[-1] == 1:\n",
        "        array = np.expand_dims(array, axis=-1)\n",
        "      array = pad_to_shape(array)\n",
        "      input_cat_tensor = tf.keras.utils.to_categorical(array, num_classes=10)\n",
        "      current_test_solver_inputs.append(input_cat_tensor)\n",
        "\n",
        "      # TEST OUTPUTS\n",
        "      array = np.array(solution_data[id][i])\n",
        "\n",
        "      if array.shape[-1] == 1:\n",
        "        array = np.expand_dims(array, axis=-1)\n",
        "      array = pad_to_shape(array)\n",
        "      output_cat_tensor = tf.keras.utils.to_categorical(array, num_classes=10)\n",
        "\n",
        "      current_test_solver_outputs.append(output_cat_tensor)\n",
        "\n",
        "    current_test_solver_inputs = np.array(current_test_solver_inputs)\n",
        "    test_solver_inputs.append(current_test_solver_inputs)\n",
        "\n",
        "    current_test_solver_outputs = np.array(current_test_solver_outputs)\n",
        "    test_solver_outputs.append(current_test_solver_outputs)\n",
        "\n",
        "  return challenge_propositioner_inputs, train_solver_inputs, train_solver_outputs, test_solver_inputs, test_solver_outputs\n",
        "      #break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mkd47bFYeN78"
      },
      "outputs": [],
      "source": [
        "challenge_propositioner_inputs, train_solver_inputs, train_solver_outputs, test_solver_inputs, test_solver_outputs= preprocess_challenge_data(training_challenges, training_solutions)\n",
        "print(len(challenge_propositioner_inputs), len(train_solver_inputs), len(train_solver_outputs), len(test_solver_inputs), len(test_solver_outputs))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}